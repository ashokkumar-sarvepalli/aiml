{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 6914911,
          "sourceType": "datasetVersion",
          "datasetId": 3970846
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'vanguard-500-index-fund-voo:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F3970846%2F6914911%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240513%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240513T022123Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D72affd18962b315096d24d6a9eeb0c337feeb3b75ab2ee3b6dddb8ec16cd2fbccc4680ca2a4eab889907a85416a4a28f5d0f26ddbfa79b438b0fc96b83ba16deb09fbaea6d83530fa5c2d8b7bfc8e15493b7038531efc0807ef317dc5de1f2b9fff96e11a824962d8ca460f284bc24a33c04871a23bf3b14219d58a27e40bce5533355f6baecfa6e9dc2dc94cd3bcc91f9f80aef571d536d3361a1d28c56e429b70ea8c658f64819df4b907275dcff50325142b42eec50261377b391a5f2e43634b96bcbdcf2762e59b861400c350f7801988f573d72b263f96832481082915006a766119e7f847a06b37cd2a7b1a902fbccbdc3d51bf13de015d49f38d3cd72'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "P5i_GXT8wTks"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-13T01:46:59.683401Z",
          "iopub.execute_input": "2024-05-13T01:46:59.683863Z",
          "iopub.status.idle": "2024-05-13T01:46:59.695962Z",
          "shell.execute_reply.started": "2024-05-13T01:46:59.683828Z",
          "shell.execute_reply": "2024-05-13T01:46:59.694723Z"
        },
        "trusted": true,
        "id": "dnm2n-J9wTku",
        "outputId": "dcfce2f9-a012-4dfd-81ea-8a4f53932255"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/vanguard-500-index-fund-voo/VOO Stock Data.csv\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install necessary packages"
      ],
      "metadata": {
        "id": "FtapfCF5wTkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas matplotlib scikit-learn tensorflow"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:46:59.698242Z",
          "iopub.execute_input": "2024-05-13T01:46:59.698616Z",
          "iopub.status.idle": "2024-05-13T01:47:12.512517Z",
          "shell.execute_reply.started": "2024-05-13T01:46:59.698576Z",
          "shell.execute_reply": "2024-05-13T01:47:12.5109Z"
        },
        "trusted": true,
        "id": "5YmaMXIRwTkw",
        "outputId": "23d68187-1cdc-4b91-eefd-76c26e86fa72"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.15.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read the data"
      ],
      "metadata": {
        "id": "nGiPJF9twTkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/kaggle/input/vanguard-500-index-fund-voo/VOO Stock Data.csv')\n",
        "df.head(10)\n",
        "print(df.head(10))\n",
        "print(df.describe())\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:12.515639Z",
          "iopub.execute_input": "2024-05-13T01:47:12.516196Z",
          "iopub.status.idle": "2024-05-13T01:47:12.564105Z",
          "shell.execute_reply.started": "2024-05-13T01:47:12.516147Z",
          "shell.execute_reply": "2024-05-13T01:47:12.562758Z"
        },
        "trusted": true,
        "id": "6Y3-5pe7wTky",
        "outputId": "a9ae57eb-2cd1-419c-b6de-13091b30e39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "       Date    Open      High      Low   Close     Volume\n0  11/07/23  400.26  402.0400  399.230  401.34  3352630.0\n1  11/06/23  400.12  400.7330  398.460  400.21  4007105.0\n2  11/03/23  397.92  400.8500  397.840  399.44  5981435.0\n3  11/02/23  391.93  395.9096  391.920  395.78  4752164.0\n4  11/01/23  385.09  389.0800  384.620  388.40  5549159.0\n5  10/31/23  382.35  384.4800  380.560  384.17  4523160.0\n6  10/30/23  379.91  382.8000  378.710  381.86  5795761.0\n7  10/27/23  380.53  380.8900  375.945  377.32  5638752.0\n8  10/26/23  382.63  383.3971  378.150  379.00  6959401.0\n9  10/25/23  387.60  387.6800  383.120  383.71  5471214.0\n              Open         High          Low        Close        Volume\ncount  3314.000000  3314.000000  3314.000000  3314.000000  3.314000e+03\nmean    237.215078   238.458956   235.841214   237.242470  2.546310e+06\nstd      94.659605    95.271351    94.002811    94.668877  2.360743e+06\nmin      99.140000   101.860000    98.240000   100.340000  8.638000e+03\n25%     165.347500   165.932500   164.419000   165.452500  9.354995e+05\n50%     217.645000   218.285000   216.385000   217.400000  2.060530e+06\n75%     304.312500   305.377500   302.217500   304.330000  3.421380e+06\nmax     440.580000   441.260000   437.655000   439.250000  2.466926e+07\nDate        object\n Open      float64\n High      float64\n Low       float64\n Close     float64\n Volume    float64\ndtype: object\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.strip()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:12.565805Z",
          "iopub.execute_input": "2024-05-13T01:47:12.566254Z",
          "iopub.status.idle": "2024-05-13T01:47:12.572297Z",
          "shell.execute_reply.started": "2024-05-13T01:47:12.566212Z",
          "shell.execute_reply": "2024-05-13T01:47:12.57099Z"
        },
        "trusted": true,
        "id": "Ma82rQYHwTkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df.sort_values('Date', inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:12.575429Z",
          "iopub.execute_input": "2024-05-13T01:47:12.575921Z",
          "iopub.status.idle": "2024-05-13T01:47:12.801468Z",
          "shell.execute_reply.started": "2024-05-13T01:47:12.575879Z",
          "shell.execute_reply": "2024-05-13T01:47:12.800095Z"
        },
        "trusted": true,
        "id": "trBpsHQFwTkz",
        "outputId": "46c47df2-ad3a-4298-bee3-b7cce18c7c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_33/1894350371.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n  df['Date'] = pd.to_datetime(df['Date'])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:12.803035Z",
          "iopub.execute_input": "2024-05-13T01:47:12.803403Z",
          "iopub.status.idle": "2024-05-13T01:47:12.813082Z",
          "shell.execute_reply.started": "2024-05-13T01:47:12.803372Z",
          "shell.execute_reply": "2024-05-13T01:47:12.811858Z"
        },
        "trusted": true,
        "id": "S3Rk2ZAwwTk0",
        "outputId": "da973389-fab7-4a71-cdd0-b72e4fc2f22a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Date      datetime64[ns]\nOpen             float64\nHigh             float64\nLow              float64\nClose            float64\nVolume           float64\ndtype: object"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:12.814558Z",
          "iopub.execute_input": "2024-05-13T01:47:12.815017Z",
          "iopub.status.idle": "2024-05-13T01:47:12.827323Z",
          "shell.execute_reply.started": "2024-05-13T01:47:12.814976Z",
          "shell.execute_reply": "2024-05-13T01:47:12.826185Z"
        },
        "trusted": true,
        "id": "ruAcd8-JwTk1",
        "outputId": "2b2a949b-da1e-4da1-fdd8-adb9a230ba86"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Date      0\nOpen      0\nHigh      0\nLow       0\nClose     0\nVolume    0\ndtype: int64\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:12.828969Z",
          "iopub.execute_input": "2024-05-13T01:47:12.82934Z",
          "iopub.status.idle": "2024-05-13T01:47:12.842349Z",
          "shell.execute_reply.started": "2024-05-13T01:47:12.829308Z",
          "shell.execute_reply": "2024-05-13T01:47:12.841107Z"
        },
        "trusted": true,
        "id": "Sqq_jUWNwTk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use 'Date' as a numeric feature by converting it to the number of days since the start date\n",
        "df['Time'] = (df['Date'] - df['Date'].min()).dt.days"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:12.843605Z",
          "iopub.execute_input": "2024-05-13T01:47:12.844009Z",
          "iopub.status.idle": "2024-05-13T01:47:12.857838Z",
          "shell.execute_reply.started": "2024-05-13T01:47:12.843977Z",
          "shell.execute_reply": "2024-05-13T01:47:12.856353Z"
        },
        "trusted": true,
        "id": "iHwp3fxOwTk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:12.859472Z",
          "iopub.execute_input": "2024-05-13T01:47:12.859955Z",
          "iopub.status.idle": "2024-05-13T01:47:12.882902Z",
          "shell.execute_reply.started": "2024-05-13T01:47:12.859911Z",
          "shell.execute_reply": "2024-05-13T01:47:12.881342Z"
        },
        "trusted": true,
        "id": "nq0_T93HwTk2",
        "outputId": "e470c9fb-df08-4044-b270-980860b8468e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "           Date    Open    High      Low     Close   Volume  Time\n3313 2010-09-09  102.50  102.50  101.140  101.3200  26513.0     0\n3312 2010-09-10  101.68  101.86  101.296  101.7800   8638.0     1\n3311 2010-09-13  102.96  103.14  102.500  103.0600  33752.5     4\n3310 2010-09-14  102.84  103.48  102.380  103.0380  59420.0     5\n3309 2010-09-15  102.62  103.38  102.400  103.3000   9283.0     6\n3308 2010-09-16  103.02  103.32  102.700  103.2600  59580.5     7\n3307 2010-09-17  103.88  103.88  103.020  103.3600  49365.0     8\n3306 2010-09-20  103.74  105.04  103.460  105.0400  19006.0    11\n3305 2010-09-21  105.02  105.44  104.280  104.7198  19286.5    12\n3304 2010-09-22  104.56  105.04  103.960  104.1600  18148.0    13",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3313</th>\n      <td>2010-09-09</td>\n      <td>102.50</td>\n      <td>102.50</td>\n      <td>101.140</td>\n      <td>101.3200</td>\n      <td>26513.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3312</th>\n      <td>2010-09-10</td>\n      <td>101.68</td>\n      <td>101.86</td>\n      <td>101.296</td>\n      <td>101.7800</td>\n      <td>8638.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3311</th>\n      <td>2010-09-13</td>\n      <td>102.96</td>\n      <td>103.14</td>\n      <td>102.500</td>\n      <td>103.0600</td>\n      <td>33752.5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3310</th>\n      <td>2010-09-14</td>\n      <td>102.84</td>\n      <td>103.48</td>\n      <td>102.380</td>\n      <td>103.0380</td>\n      <td>59420.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3309</th>\n      <td>2010-09-15</td>\n      <td>102.62</td>\n      <td>103.38</td>\n      <td>102.400</td>\n      <td>103.3000</td>\n      <td>9283.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3308</th>\n      <td>2010-09-16</td>\n      <td>103.02</td>\n      <td>103.32</td>\n      <td>102.700</td>\n      <td>103.2600</td>\n      <td>59580.5</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3307</th>\n      <td>2010-09-17</td>\n      <td>103.88</td>\n      <td>103.88</td>\n      <td>103.020</td>\n      <td>103.3600</td>\n      <td>49365.0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>3306</th>\n      <td>2010-09-20</td>\n      <td>103.74</td>\n      <td>105.04</td>\n      <td>103.460</td>\n      <td>105.0400</td>\n      <td>19006.0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3305</th>\n      <td>2010-09-21</td>\n      <td>105.02</td>\n      <td>105.44</td>\n      <td>104.280</td>\n      <td>104.7198</td>\n      <td>19286.5</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>3304</th>\n      <td>2010-09-22</td>\n      <td>104.56</td>\n      <td>105.04</td>\n      <td>103.960</td>\n      <td>104.1600</td>\n      <td>18148.0</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(-10)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:12.887048Z",
          "iopub.execute_input": "2024-05-13T01:47:12.888143Z",
          "iopub.status.idle": "2024-05-13T01:47:12.909039Z",
          "shell.execute_reply.started": "2024-05-13T01:47:12.888088Z",
          "shell.execute_reply": "2024-05-13T01:47:12.907701Z"
        },
        "trusted": true,
        "id": "9imMK6-wwTk2",
        "outputId": "2073cd21-b623-4c81-e3ae-6d0e507d6094"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "           Date     Open      High      Low     Close     Volume  Time\n3303 2010-09-23  103.320  104.3400  103.120  103.3062    33358.0    14\n3302 2010-09-24  103.940  104.9000  103.868  104.8400    24126.5    15\n3301 2010-09-27  104.980  104.9800  104.340  104.3400    15044.5    18\n3300 2010-09-28  104.318  105.0200  103.420  105.0200    49853.0    19\n3299 2010-09-29  104.580  104.9100  104.220  104.5200    15890.0    20\n...         ...      ...       ...      ...       ...        ...   ...\n4    2023-11-01  385.090  389.0800  384.620  388.4000  5549159.0  4801\n3    2023-11-02  391.930  395.9096  391.920  395.7800  4752164.0  4802\n2    2023-11-03  397.920  400.8500  397.840  399.4400  5981435.0  4803\n1    2023-11-06  400.120  400.7330  398.460  400.2100  4007105.0  4806\n0    2023-11-07  400.260  402.0400  399.230  401.3400  3352630.0  4807\n\n[3304 rows x 7 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Volume</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3303</th>\n      <td>2010-09-23</td>\n      <td>103.320</td>\n      <td>104.3400</td>\n      <td>103.120</td>\n      <td>103.3062</td>\n      <td>33358.0</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3302</th>\n      <td>2010-09-24</td>\n      <td>103.940</td>\n      <td>104.9000</td>\n      <td>103.868</td>\n      <td>104.8400</td>\n      <td>24126.5</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>3301</th>\n      <td>2010-09-27</td>\n      <td>104.980</td>\n      <td>104.9800</td>\n      <td>104.340</td>\n      <td>104.3400</td>\n      <td>15044.5</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3300</th>\n      <td>2010-09-28</td>\n      <td>104.318</td>\n      <td>105.0200</td>\n      <td>103.420</td>\n      <td>105.0200</td>\n      <td>49853.0</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>3299</th>\n      <td>2010-09-29</td>\n      <td>104.580</td>\n      <td>104.9100</td>\n      <td>104.220</td>\n      <td>104.5200</td>\n      <td>15890.0</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-11-01</td>\n      <td>385.090</td>\n      <td>389.0800</td>\n      <td>384.620</td>\n      <td>388.4000</td>\n      <td>5549159.0</td>\n      <td>4801</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-11-02</td>\n      <td>391.930</td>\n      <td>395.9096</td>\n      <td>391.920</td>\n      <td>395.7800</td>\n      <td>4752164.0</td>\n      <td>4802</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-11-03</td>\n      <td>397.920</td>\n      <td>400.8500</td>\n      <td>397.840</td>\n      <td>399.4400</td>\n      <td>5981435.0</td>\n      <td>4803</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-11-06</td>\n      <td>400.120</td>\n      <td>400.7330</td>\n      <td>398.460</td>\n      <td>400.2100</td>\n      <td>4007105.0</td>\n      <td>4806</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2023-11-07</td>\n      <td>400.260</td>\n      <td>402.0400</td>\n      <td>399.230</td>\n      <td>401.3400</td>\n      <td>3352630.0</td>\n      <td>4807</td>\n    </tr>\n  </tbody>\n</table>\n<p>3304 rows × 7 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = np.array(df['Time']).reshape(-1, 1)  # Reshape for sklearn compatibility\n",
        "y = np.array(df['Close']).reshape(-1, 1)\n",
        "\n",
        "print(\"Minimum value in y:\", np.min(y))\n",
        "print(\"Maximum value in y:\", np.max(y))\n",
        "\n",
        "print(X)\n",
        "print(y)\n",
        "\n",
        "# Normalize the features\n",
        "scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
        "print(scaler_x)\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
        "print(scaler_x)\n",
        "X_scaled = scaler_x.fit_transform(X)\n",
        "print(X_scaled)\n",
        "y_scaled = scaler_y.fit_transform(y)\n",
        "print(y_scaled)\n",
        "print(y_scaled[0])\n",
        "print(y_scaled[len(y_scaled)-1])\n",
        "\n",
        "print(\"Scaled minimum:\", np.min(y_scaled))\n",
        "print(\"Scaled maximum:\", np.max(y_scaled))\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
        "print(X_train)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:12.910363Z",
          "iopub.execute_input": "2024-05-13T01:47:12.910821Z",
          "iopub.status.idle": "2024-05-13T01:47:12.929424Z",
          "shell.execute_reply.started": "2024-05-13T01:47:12.910778Z",
          "shell.execute_reply": "2024-05-13T01:47:12.928163Z"
        },
        "trusted": true,
        "id": "1QZ_sLjVwTk3",
        "outputId": "961722cc-1388-4c1b-c4ef-884a64c27b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Minimum value in y: 100.34\nMaximum value in y: 439.25\n[[   0]\n [   1]\n [   4]\n ...\n [4803]\n [4806]\n [4807]]\n[[101.32]\n [101.78]\n [103.06]\n ...\n [399.44]\n [400.21]\n [401.34]]\nMinMaxScaler()\nMinMaxScaler()\n[[0.00000000e+00]\n [2.08029956e-04]\n [8.32119825e-04]\n ...\n [9.99167880e-01]\n [9.99791970e-01]\n [1.00000000e+00]]\n[[0.00289162]\n [0.00424892]\n [0.00802573]\n ...\n [0.88253519]\n [0.88480718]\n [0.88814139]]\n[0.00289162]\n[0.88814139]\nScaled minimum: 0.0\nScaled maximum: 1.0000000000000002\n[[0.44060745]\n [0.16101519]\n [0.51716247]\n ...\n [0.3902642 ]\n [0.26003745]\n [0.95818598]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "k6hSL2QlwTk3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multilayer Perceptron (MLP) Simple Dense Predictor"
      ],
      "metadata": {
        "id": "dncAIIdrwTk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Dense(50, input_dim=1, activation='relu'),\n",
        "    Dense(20, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:12.930642Z",
          "iopub.execute_input": "2024-05-13T01:47:12.931041Z",
          "iopub.status.idle": "2024-05-13T01:47:13.011053Z",
          "shell.execute_reply.started": "2024-05-13T01:47:12.93101Z",
          "shell.execute_reply": "2024-05-13T01:47:13.009837Z"
        },
        "trusted": true,
        "id": "LuzMT9yBwTk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=1, validation_split=0.2)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:13.012258Z",
          "iopub.execute_input": "2024-05-13T01:47:13.012574Z",
          "iopub.status.idle": "2024-05-13T01:47:38.160839Z",
          "shell.execute_reply.started": "2024-05-13T01:47:13.01254Z",
          "shell.execute_reply": "2024-05-13T01:47:38.159812Z"
        },
        "trusted": true,
        "id": "vwsSpVc2wTk4",
        "outputId": "8d199335-761e-4974-87f9-aab7d5513e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/50\n212/212 [==============================] - 1s 3ms/step - loss: 0.0133 - val_loss: 0.0051\nEpoch 2/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0051 - val_loss: 0.0044\nEpoch 3/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0042\nEpoch 4/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0043 - val_loss: 0.0036\nEpoch 5/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0034\nEpoch 6/50\n212/212 [==============================] - 1s 3ms/step - loss: 0.0037 - val_loss: 0.0033\nEpoch 7/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0032\nEpoch 8/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0030\nEpoch 9/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0029\nEpoch 10/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0029\nEpoch 11/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0029\nEpoch 12/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0030\nEpoch 13/50\n212/212 [==============================] - 1s 3ms/step - loss: 0.0031 - val_loss: 0.0029\nEpoch 14/50\n212/212 [==============================] - 1s 3ms/step - loss: 0.0030 - val_loss: 0.0032\nEpoch 15/50\n212/212 [==============================] - 1s 3ms/step - loss: 0.0029 - val_loss: 0.0026\nEpoch 16/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0028 - val_loss: 0.0026\nEpoch 17/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0025\nEpoch 18/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0027 - val_loss: 0.0025\nEpoch 19/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0022\nEpoch 20/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0021\nEpoch 21/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0024 - val_loss: 0.0022\nEpoch 22/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0021\nEpoch 23/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0019\nEpoch 24/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0021\nEpoch 25/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0018\nEpoch 26/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0018\nEpoch 27/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0020\nEpoch 28/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0021\nEpoch 29/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0019\nEpoch 30/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0020 - val_loss: 0.0017\nEpoch 31/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0017\nEpoch 32/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0017\nEpoch 33/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0017\nEpoch 34/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 0.0017\nEpoch 35/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0016\nEpoch 36/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0017\nEpoch 37/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0018\nEpoch 38/50\n212/212 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0016\nEpoch 39/50\n212/212 [==============================] - 1s 3ms/step - loss: 0.0018 - val_loss: 0.0018\nEpoch 40/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0021\nEpoch 41/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0015\nEpoch 42/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0015\nEpoch 43/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0015\nEpoch 44/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0015\nEpoch 45/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0018\nEpoch 46/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0016\nEpoch 47/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0020\nEpoch 48/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0015\nEpoch 49/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0019 - val_loss: 0.0017\nEpoch 50/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0018 - val_loss: 0.0017\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Make predictions\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "\n",
        "# Inverse transform predictions\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "y_actual = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_actual, y_pred))\n",
        "print(\"RMSE: \", rmse)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:38.162479Z",
          "iopub.execute_input": "2024-05-13T01:47:38.162879Z",
          "iopub.status.idle": "2024-05-13T01:47:38.333407Z",
          "shell.execute_reply.started": "2024-05-13T01:47:38.162848Z",
          "shell.execute_reply": "2024-05-13T01:47:38.332213Z"
        },
        "trusted": true,
        "id": "PNh6eDyZwTk4",
        "outputId": "5161373c-b0e8-43e8-a183-992fdbd7d721"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "21/21 [==============================] - 0s 2ms/step\nRMSE:  14.248296640758788\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.max())\n",
        "future_times = np.array([X.max() + 365 * i for i in range(1, 11)]).reshape(-1, 1)\n",
        "future_times_scaled = scaler_x.transform(future_times)\n",
        "future_predictions_scaled = model.predict(future_times_scaled)\n",
        "future_predictions = scaler_y.inverse_transform(future_predictions_scaled)\n",
        "\n",
        "print(\"Future Predictions for the next 10 years:\")\n",
        "print(future_predictions)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:38.334924Z",
          "iopub.execute_input": "2024-05-13T01:47:38.335361Z",
          "iopub.status.idle": "2024-05-13T01:47:38.428572Z",
          "shell.execute_reply.started": "2024-05-13T01:47:38.33531Z",
          "shell.execute_reply": "2024-05-13T01:47:38.42736Z"
        },
        "trusted": true,
        "id": "gNVF2rrtwTk5",
        "outputId": "2c896003-c31b-481d-fd85-4d5bafbaebd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "4807\n1/1 [==============================] - 0s 22ms/step\nFuture Predictions for the next 10 years:\n[[359.04218]\n [349.22757]\n [339.41296]\n [329.59842]\n [319.7838 ]\n [309.96924]\n [299.4777 ]\n [289.0683 ]\n [278.6192 ]\n [268.17007]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leaky ReLU"
      ],
      "metadata": {
        "id": "-ARxu6ApwTk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LeakyReLU, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Dense(50, input_dim=1),\n",
        "    LeakyReLU(alpha=0.01),  # Specify LeakyReLU as a layer with a small slope for negative inputs\n",
        "    Dense(20),\n",
        "    LeakyReLU(alpha=0.01),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=1, validation_split=0.2)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Make predictions\n",
        "y_pred_scaled = model.predict(X_test)\n",
        "\n",
        "# Inverse transform predictions\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "y_actual = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_actual, y_pred))\n",
        "print(\"RMSE: \", rmse)\n",
        "print(X.max())\n",
        "future_times = np.array([X.max() + 365 * i for i in range(1, 11)]).reshape(-1, 1)\n",
        "future_times_scaled = scaler_x.transform(future_times)\n",
        "future_predictions_scaled = model.predict(future_times_scaled)\n",
        "future_predictions = scaler_y.inverse_transform(future_predictions_scaled)\n",
        "\n",
        "print(\"Future Predictions for the next 10 years:\")\n",
        "print(future_predictions)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T02:17:53.514922Z",
          "iopub.execute_input": "2024-05-13T02:17:53.515446Z",
          "iopub.status.idle": "2024-05-13T02:18:18.853783Z",
          "shell.execute_reply.started": "2024-05-13T02:17:53.515402Z",
          "shell.execute_reply": "2024-05-13T02:18:18.852277Z"
        },
        "trusted": true,
        "id": "9enRSI5GwTk5",
        "outputId": "d9ba1eb3-171b-4bbf-bc39-e3d4deaaba55"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0321 - val_loss: 0.0050\nEpoch 2/50\n212/212 [==============================] - 1s 3ms/step - loss: 0.0052 - val_loss: 0.0045\nEpoch 3/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0049 - val_loss: 0.0042\nEpoch 4/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0041\nEpoch 5/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0037\nEpoch 6/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0040 - val_loss: 0.0036\nEpoch 7/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0036\nEpoch 8/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0038\nEpoch 9/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0034\nEpoch 10/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0038 - val_loss: 0.0035\nEpoch 11/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0035\nEpoch 12/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0038 - val_loss: 0.0034\nEpoch 13/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0034\nEpoch 14/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0035\nEpoch 15/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0042\nEpoch 16/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0037 - val_loss: 0.0032\nEpoch 17/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0033\nEpoch 18/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0034\nEpoch 19/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0031\nEpoch 20/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0031\nEpoch 21/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0035 - val_loss: 0.0034\nEpoch 22/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0033\nEpoch 23/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0031\nEpoch 24/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0033\nEpoch 25/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0029\nEpoch 26/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0031\nEpoch 27/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0028\nEpoch 28/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0031\nEpoch 29/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0027\nEpoch 30/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0032 - val_loss: 0.0028\nEpoch 31/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0032\nEpoch 32/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0026\nEpoch 33/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0030 - val_loss: 0.0028\nEpoch 34/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0031 - val_loss: 0.0027\nEpoch 35/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0027\nEpoch 36/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0024\nEpoch 37/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0026\nEpoch 38/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0028 - val_loss: 0.0028\nEpoch 39/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0027 - val_loss: 0.0027\nEpoch 40/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0022\nEpoch 41/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0021\nEpoch 42/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0026 - val_loss: 0.0023\nEpoch 43/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0025 - val_loss: 0.0023\nEpoch 44/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0024 - val_loss: 0.0021\nEpoch 45/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0023 - val_loss: 0.0022\nEpoch 46/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0023\nEpoch 47/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0022 - val_loss: 0.0019\nEpoch 48/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0022 - val_loss: 0.0019\nEpoch 49/50\n212/212 [==============================] - 1s 2ms/step - loss: 0.0021 - val_loss: 0.0018\nEpoch 50/50\n212/212 [==============================] - 0s 2ms/step - loss: 0.0021 - val_loss: 0.0020\n21/21 [==============================] - 0s 2ms/step\nRMSE:  15.720786758934489\n4807\n1/1 [==============================] - 0s 23ms/step\nFuture Predictions for the next 10 years:\n[[400.10913]\n [404.79523]\n [409.64243]\n [414.12088]\n [417.55313]\n [418.7763 ]\n [419.99957]\n [421.22275]\n [422.44595]\n [423.6692 ]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM RNN Neural network training"
      ],
      "metadata": {
        "id": "YNLo90ucwTk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X2cm7t_twTk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b02CbJufwTk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "# Assuming X_train, y_train are properly scaled and ready for training\n",
        "model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(1, 1)),\n",
        "    LSTM(50),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "model.fit(X_train_lstm, y_train, epochs=50, batch_size=10, verbose=1, validation_split=0.2)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:47:38.430117Z",
          "iopub.execute_input": "2024-05-13T01:47:38.430624Z",
          "iopub.status.idle": "2024-05-13T01:48:31.193137Z",
          "shell.execute_reply.started": "2024-05-13T01:47:38.430581Z",
          "shell.execute_reply": "2024-05-13T01:48:31.191995Z"
        },
        "trusted": true,
        "id": "Gnfr3uSPwTk7",
        "outputId": "28075bb7-1ce4-4011-f396-55ee0c08be0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/50\n212/212 [==============================] - 5s 9ms/step - loss: 0.0518 - val_loss: 0.0044\nEpoch 2/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0044\nEpoch 3/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0047 - val_loss: 0.0041\nEpoch 4/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0046\nEpoch 5/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0047 - val_loss: 0.0041\nEpoch 6/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0045\nEpoch 7/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0045\nEpoch 8/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0042\nEpoch 9/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0041\nEpoch 10/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0041\nEpoch 11/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0054\nEpoch 12/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0048 - val_loss: 0.0041\nEpoch 13/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0052\nEpoch 14/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0042\nEpoch 15/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0041\nEpoch 16/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0043\nEpoch 17/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0042\nEpoch 18/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0041\nEpoch 19/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0041\nEpoch 20/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0041\nEpoch 21/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0041\nEpoch 22/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0048 - val_loss: 0.0043\nEpoch 23/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0046\nEpoch 24/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0047 - val_loss: 0.0041\nEpoch 25/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0047 - val_loss: 0.0041\nEpoch 26/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0052\nEpoch 27/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0041\nEpoch 28/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0042\nEpoch 29/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0046\nEpoch 30/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0045\nEpoch 31/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0047 - val_loss: 0.0046\nEpoch 32/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0057\nEpoch 33/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0048 - val_loss: 0.0045\nEpoch 34/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0041\nEpoch 35/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0041\nEpoch 36/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0047\nEpoch 37/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0044\nEpoch 38/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0043\nEpoch 39/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0042\nEpoch 40/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.0041\nEpoch 41/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0047\nEpoch 42/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.0046\nEpoch 43/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0045\nEpoch 44/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0041\nEpoch 45/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0041\nEpoch 46/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0043\nEpoch 47/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0042\nEpoch 48/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0041\nEpoch 49/50\n212/212 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0044\nEpoch 50/50\n212/212 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0045\n",
          "output_type": "stream"
        },
        {
          "execution_count": 41,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.src.callbacks.History at 0x7cc20cfd7f10>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of the model"
      ],
      "metadata": {
        "id": "qA4u44xjwTk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting with test data\n",
        "y_pred_scaled = model.predict(X_test_lstm)\n",
        "\n",
        "# Inverse transform the predicted values to original scale\n",
        "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
        "y_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))  # Ensure y_test is properly reshaped for inverse transform\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_actual, y_pred))\n",
        "print(\"RMSE on Test Data: \", rmse)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:48:31.194582Z",
          "iopub.execute_input": "2024-05-13T01:48:31.195011Z",
          "iopub.status.idle": "2024-05-13T01:48:32.14968Z",
          "shell.execute_reply.started": "2024-05-13T01:48:31.194973Z",
          "shell.execute_reply": "2024-05-13T01:48:32.148516Z"
        },
        "trusted": true,
        "id": "1KcSD4sCwTk7",
        "outputId": "333716d7-060c-40d4-fc5c-5bb0260afde0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "21/21 [==============================] - 1s 3ms/step\nRMSE on Test Data:  21.727497487365362\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction of the model"
      ],
      "metadata": {
        "id": "1e5_R2kBwTk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "future_times_scaled = scaler_x.transform(future_times.reshape(-1, 1))\n",
        "future_times_scaled_lstm = future_times_scaled.reshape((future_times_scaled.shape[0], 1, future_times_scaled.shape[1]))\n",
        "future_predictions_scaled = model.predict(future_times_scaled_lstm)\n",
        "future_predictions = scaler_y.inverse_transform(future_predictions_scaled)\n",
        "\n",
        "print(\"Future Predictions for the next 10 years:\")\n",
        "print(future_predictions)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:48:32.151373Z",
          "iopub.execute_input": "2024-05-13T01:48:32.151871Z",
          "iopub.status.idle": "2024-05-13T01:48:32.243583Z",
          "shell.execute_reply.started": "2024-05-13T01:48:32.151828Z",
          "shell.execute_reply": "2024-05-13T01:48:32.242297Z"
        },
        "trusted": true,
        "id": "PZ3P6VJiwTk7",
        "outputId": "377c7bdc-7c47-4c98-c591-873f43d8f78f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "1/1 [==============================] - 0s 25ms/step\nFuture Predictions for the next 10 years:\n[[449.26926]\n [487.81937]\n [527.89124]\n [569.3219 ]\n [611.932  ]\n [655.5306 ]\n [699.9181 ]\n [744.8916 ]\n [790.2486 ]\n [835.7903 ]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'])  # Convert Date column to datetime if not already\n",
        "\n",
        "# Calculate the maximum date and add one year\n",
        "max_date = df['Date'].max()\n",
        "start_date = pd.Timestamp(year=max_date.year - 1, month=1, day=1)\n",
        "\n",
        "# Create a DataFrame for the predicted values\n",
        "years = pd.date_range(start=start_date + pd.DateOffset(years=1), periods=10, freq='Y')\n",
        "future_df = pd.DataFrame({\n",
        "    'Year': years.year,\n",
        "    'Predicted Close': [x[0] for x in future_predictions]\n",
        "})\n",
        "\n",
        "# Display the DataFrame\n",
        "print(future_df)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:48:32.245528Z",
          "iopub.execute_input": "2024-05-13T01:48:32.24592Z",
          "iopub.status.idle": "2024-05-13T01:48:32.262706Z",
          "shell.execute_reply.started": "2024-05-13T01:48:32.245888Z",
          "shell.execute_reply": "2024-05-13T01:48:32.261482Z"
        },
        "trusted": true,
        "id": "3i_COOD5wTk8",
        "outputId": "065b226c-ca3e-4944-de79-84b7422921a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "   Year  Predicted Close\n0  2023       449.269257\n1  2024       487.819366\n2  2025       527.891235\n3  2026       569.321899\n4  2027       611.932007\n5  2028       655.530579\n6  2029       699.918091\n7  2030       744.891602\n8  2031       790.248596\n9  2032       835.790283\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_33/611044417.py:10: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n  years = pd.date_range(start=start_date + pd.DateOffset(years=1), periods=10, freq='Y')\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage increase compared to the previous year\n",
        "future_df['Percentage Increase'] = future_df['Predicted Close'].pct_change() * 100"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:48:32.264231Z",
          "iopub.execute_input": "2024-05-13T01:48:32.265102Z",
          "iopub.status.idle": "2024-05-13T01:48:32.285189Z",
          "shell.execute_reply.started": "2024-05-13T01:48:32.265066Z",
          "shell.execute_reply": "2024-05-13T01:48:32.28384Z"
        },
        "trusted": true,
        "id": "O_r6XPmrwTk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_year = 2023\n",
        "# CAGR calculation\n",
        "start_price = future_df.loc[0, 'Predicted Close']\n",
        "# Calculate CAGR from the start year to each year\n",
        "future_df['CAGR from Start (%)'] = ((future_df['Predicted Close'] / start_price) **\n",
        "                                     (1 / (future_df['Year'] - start_year)) - 1) * 100\n",
        "\n",
        "# Fix the value for the starting year to NaN since it's the initial year (no growth to calculate)\n",
        "future_df.loc[future_df['Year'] == start_year, 'CAGR from Start (%)'] = np.nan"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:48:32.286653Z",
          "iopub.execute_input": "2024-05-13T01:48:32.287116Z",
          "iopub.status.idle": "2024-05-13T01:48:32.302912Z",
          "shell.execute_reply.started": "2024-05-13T01:48:32.287081Z",
          "shell.execute_reply": "2024-05-13T01:48:32.301685Z"
        },
        "trusted": true,
        "id": "0ES-p-9HwTk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(future_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-13T01:48:32.304281Z",
          "iopub.execute_input": "2024-05-13T01:48:32.304635Z",
          "iopub.status.idle": "2024-05-13T01:48:32.320114Z",
          "shell.execute_reply.started": "2024-05-13T01:48:32.304604Z",
          "shell.execute_reply": "2024-05-13T01:48:32.318708Z"
        },
        "trusted": true,
        "id": "OeVe3wbvwTk8",
        "outputId": "a372ce2d-74c2-4789-aed2-3992657cc2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "   Year  Predicted Close  Percentage Increase  CAGR from Start (%)\n0  2023       449.269257                  NaN                  NaN\n1  2024       487.819366             8.580626             8.580625\n2  2025       527.891235             8.214485             8.397404\n3  2026       569.321899             7.848334             8.214071\n4  2027       611.932007             7.484365             8.031178\n5  2028       655.530579             7.124746             7.849281\n6  2029       699.918091             6.771231             7.668853\n7  2030       744.891602             6.425536             7.490351\n8  2031       790.248596             6.089067             7.314184\n9  2032       835.790283             5.762959             7.140709\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}